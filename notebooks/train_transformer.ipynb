{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rd804/particle_transformer')\n",
    "import networks.example_ParticleTransformer as part\n",
    "import networks.example_ParticleTransformer_finetune as part_finetune\n",
    "from weaver.utils.dataset import DataConfig\n",
    "import torch\n",
    "from weaver.nn.model.ParticleTransformer import ParticleTransformer\n",
    "from weaver.utils.logger import _logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rd804/particle_transformer\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config_file = 'data/JetClass/JetClass_full.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig.load(data_config_file, load_observers=False, load_reweight_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of parameters\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 10\n",
      "The model has 1,290 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model, model_info = part_finetune.get_model(data_config)\n",
    "model.to(device)\n",
    "model.mod.requires_grad_(False)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,143,486 trainable parameters\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd = h5py.File(\"data/JetClass/qcd_N30_100k.hdf5\",'r')['4_momenta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd = np.array(qcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 30, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd = qcd[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 30]) torch.Size([5, 10, 30]) torch.Size([5, 1, 30])\n"
     ]
    }
   ],
   "source": [
    "vector = qcd[:,:,:4]\n",
    "features = qcd[:,:,4:]\n",
    "mask = torch.tensor((vector!=[0,0,0,0])[...,0]).unsqueeze(-1)\n",
    "\n",
    "vector_ = torch.from_numpy(vector).float().to(device)\n",
    "features_ = torch.from_numpy(features).float().to(device)\n",
    "mask_ = mask.to(torch.bool).to(device)\n",
    "\n",
    "\n",
    "vector = torch.swapaxes(vector_, 1, 2)\n",
    "features = torch.swapaxes(features_, 1, 2)\n",
    "mask = torch.swapaxes(mask_, 1, 2)\n",
    "#vector = vector_.reshape(-1, 4, 30)\n",
    "#features = features_.reshape(-1, 10, 30)\n",
    "#mask = mask_.reshape(-1, 1, 30)\n",
    "\n",
    "print(vector.shape, features.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_[0][:,0] == vector[0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 31.2660,  29.5754,  24.3738,  19.7528,  19.4773,  14.8039,  14.3368,\n",
       "          14.3163,   9.8281,  10.3337,   9.7158,   9.4207,   9.1491,   8.8331,\n",
       "           8.6541,   7.9766,   6.1533,   6.2985,   6.5550,   5.7657,   4.9204,\n",
       "           4.4619,   2.9796,   3.8783,   3.8842,   3.1165,   2.1151,   2.6623,\n",
       "           2.4259,   2.6129],\n",
       "        [-38.0751, -39.2075, -28.7359, -25.5304, -24.0376, -19.0401, -18.4265,\n",
       "         -17.9181, -13.0966, -11.8702, -12.3258, -11.9550, -11.4691, -11.4601,\n",
       "         -11.4354, -10.0531,  -8.7314,  -7.7697,  -7.5443,  -7.8448,  -7.3548,\n",
       "          -5.8255,  -5.7022,  -5.0602,  -4.9233,  -4.2517,  -4.4931,  -3.5276,\n",
       "          -3.6841,  -3.3233],\n",
       "        [-23.3272, -16.7902, -16.9258, -12.7473, -14.2079, -11.2024,  -8.9283,\n",
       "         -10.9013,  -5.2647,  -7.3408,  -7.5359,  -6.9933,  -6.2041,  -6.0538,\n",
       "          -5.4385,  -5.6935,  -3.5830,  -3.5607,  -3.5630,  -3.8287,  -4.0426,\n",
       "          -4.8051,  -2.1574,  -2.2782,  -2.3322,  -2.0455,  -3.0968,  -2.1580,\n",
       "          -1.9953,  -1.6593],\n",
       "        [ 54.5110,  51.9046,  41.3076,  34.7055,  34.0446,  26.5928,  25.0134,\n",
       "          25.3944,  17.2003,  17.3659,  17.4107,  16.7767,  15.9291,  15.6846,\n",
       "          15.3376,  14.0395,  11.2675,  10.6169,  10.6103,  10.4625,   9.7296,\n",
       "           8.7723,   6.7858,   6.7703,   6.7088,   5.6545,   5.8526,   4.9202,\n",
       "           4.9314,   4.5415]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ParticleTransformerWrapper.forward of ParticleTransformerWrapper(\n",
       "  (mod): ParticleTransformer(\n",
       "    (trimmer): SequenceTrimmer()\n",
       "    (embed): Embed(\n",
       "      (input_bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (embed): Sequential(\n",
       "        (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=10, out_features=128, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (7): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (8): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (pair_embed): PairEmbed(\n",
       "      (embed): Sequential(\n",
       "        (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Conv1d(64, 8, kernel_size=(1,), stride=(1,))\n",
       "        (11): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cls_blocks): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rd804/.conda/envs/part/lib/python3.10/site-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = model(features, lorentz_vectors=vector , mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_part = 'models/ParT_full.pt'\n",
    "model.load_state_dict(torch.load(path_part))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "part",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
